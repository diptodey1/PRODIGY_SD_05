from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import csv
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.keys import Keys
import time

options = Options()
options.add_argument('--headless')
options.add_argument('--window-size=1920x1080')

driver = webdriver.Chrome(options=options)

driver.get("https://www.flipkart.com/")

driver.implicitly_wait(10)

try:
    search_box = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.NAME, "q"))
    )
    search_box.send_keys("laptops")
    search_box.send_keys(Keys.RETURN)
except Exception as e:
    print(f"Error occurred while searching for product: {e}")
    driver.quit()
    exit()

time.sleep(5)

html = driver.page_source
soup = BeautifulSoup(html, 'html.parser')

products = soup.find_all('div', {'class': '_1AtVbE col-12-12 _13OCea'})

titles = []
prices = []
ratings = []

for product in products:
    try:
        title = product.find('div', {'class': '_4rR01T'}).text.strip()
        price = product.find('div', {'class': '_30jeq3 _1_WHN1'}).text.strip().replace(',', '')
        rating = product.find('div', {'class': '_3LWZlK'}).text.strip()
        titles.append(title)
        prices.append(price)
        ratings.append(rating)
    except Exception as e:
        print(f"Error occurred while extracting product data: {e}")

with open('flipkart_data.csv', 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(["Product Title", "Price", "Rating"])

    for title, price, rating in zip(titles, prices, ratings):
        writer.writerow([title, price, rating])

print("Data has been written to flipkart_data.csv")

driver.quit()
